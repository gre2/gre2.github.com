---
layout: post
title: "集合"
description: ""
category: [java,基础]
tags: [基础]
---
{% include JB/setup %}

# 集合

### 集合序列化方式

为什么实现serializable接口，writeObject的代码段

```
if (obj instanceof String) {
    writeString((String) obj, unshared);
} else if (cl.isArray()) {
    writeArray(obj, desc, unshared);
} else if (obj instanceof Enum) {
    writeEnum((Enum<?>) obj, desc, unshared);
} else if (obj instanceof Serializable) {
    writeOrdinaryObject(obj, desc, unshared);
} else {
    if (extendedDebugInfo) {
        throw new NotSerializableException(
            cl.getName() + "\n" + debugInfoStack.toString());
    } else {
        throw new NotSerializableException(cl.getName());
    }
}
```

集合的writeObject 和 readObject 方法，在使用ObjectOutputStream的writeObject方法和ObjectInputStream的readObject方法时，会通过反射的方式调用。

### HashMap

##### jdk7和jdk8的区别

- 增加了红黑树数据结构，时间复杂度从O(n)降到了O(logN)

  - 当链表长度 > 8时，转换成红黑树

- 根据传入的key计算hash

  - hashCode方法

  - 1.7 扰动处理 =9次扰动 =4次位运算 + 5次异或运算

    ```
    static final int hash(int h) {
    	h ^= k.hashCode(); 
    	h ^= (h >>> 20) ^ (h >>> 12); 
    	return h ^ (h >>> 7) ^ (h >>> 4); 
    }
    ```

  - 1.8扰动处理 =2次扰动 =1次位运算 + 1次异或运算

    ```
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
    ```

- put的时候插入方式
  - 1.7 链表头插 [为什么不插到后面，因为时间复杂度是o(n)]
  - 1.8 判定数据结构是链表还是红黑树（优先判断），如果不是红黑树，链表尾插

- 扩容

  - 1.7 不插入新数据
  - 1.8 插入

- 扩容后存储位置的计算方式

  - 1.8 扩容后的位置 = 原位置 or 原位置 + 旧容量
  - 1.7 hashCode() & length -1 

##### 解决hash碰撞

- hash算法

  - hashCode计算方式
  - 扰动函数优化（扰动次数减少，1.8 高低16位异或）
- 扩容机制
- 数据结构
  - 拉链法 ，头插
  - 拉链法，尾插，红黑树
##### 不安全

- put的时候数据覆盖

- resize形成环形链表，当相同的hash落点寻找时，死循环

##### 红黑树

- TreeNode继承LinkedHashMap.Entry<K,V>
- 最小树形化阈值，当哈希表中的容量 > 该值时，才允许将链表转换成红黑树，否则桶内元素太多，直接扩容，而不是树形化，为了避免扩容，树形化选择的冲突值不能小于 4 * TREEIFY_THRESHOLD [8]，即不能小于32，每次扩容是2的倍数，所以小于64不树形化
- 桶的树形化域 == 8
- 桶的链表还原  == 6 ，resize时，数据重新计算落点，当原有红黑树的数量 < 6，变成链表

##### 迭代器快速失败策略

- 修改次数modCount，迭代器初始化时将该值赋值给expectModCount变量，迭代时判断两个值是否相同，不同代表有人修改了hashMap

##### 位运算

&  两位都是1，才是1 ，其余都是0

^  相同为0，不同为1



##### 落点问题

- 为什么不直接采用hashcode处理的哈希码作为存储数组table的下标位置
- 数组长度为什么要是2的倍数呢
- 为什么采用哈希码 & （数组长度 - 1）计算数组下标
- 为什么在计算数组下标前，需要哈希码进行二次处理：扰动处理？

##### 落点问题解决

根本原因是为了提高K,V的随机性，分布均匀性，尽量避免hash冲突！！！

- 问题1回答：如果出现哈希码（2^31 -1）与数组大小(2^30)范围不匹配的情况，哈希码可能不在数组大小范围内，所以采用 & （数组长度 - 1）
- 实际是哈希码 % 数组长度，但是 %的效率低，为了提高运算率，只有长度是2的幂， %才和&（length-1）对等
- 如果不是length-1,那么最后一位一定是0，hash落点全都落在了偶数位，冲突加大，容量小一半，解决问题1
- 加大哈希码低位的随机性，减小hash冲突



reference：https://www.jianshu.com/p/8324a34577a0

​                     https://www.jianshu.com/p/e2f75c8cce01

​                     https://www.jianshu.com/p/7fb0b940556d



### CurrentHashMap

##### 结构

- jdk7：segment数组+hashEntry数组，并发用ReentrantLock
- jdk8：摒弃segment的概念，Node数组，链表，红黑树，并发用Synchronized和CAS来操作
  - Node（链表）只能查不能改，继续Map.Entry
  - TreeNode（红黑树）继承Node
  - TreeBin是封装TreeNode的容器，提供转换红黑树的条件和锁控制

##### put

- jdk7：segment实现了ReentrantLock，对key的hash定位segment的位置，如果segment没有初始化，通过cas操作赋值，然后第二次hash找到HashEntry，插入时，tryLock方法获取锁，如果成功插入尾部，失败自旋获取锁，超过指定次数就挂起，等待被唤醒

##### size

- jdk7：并发导致size不准，方案一：不加锁尝试计算size，最多三次，比较前后两次结果，一致认为没有数据插入，准确；方案二：如果方案一不符合，给每个segment加上锁，然后计算size

##### 思考

- 在粗粒度加锁中ReentrantLock通过Condition来控制各个低粒度的边界，锁粒度降低了，低粒度的加锁方式，synchronized并不比ReentrantLock差

### CopyOnWriteArrayList

写时复制容器，往容器新增元素的时候（上锁），不往容器加，将当前容器复制出来一个新的容器，往新的容器里面加元素，加完之后，将原容器的引用指向新的容器，好处是可以对这个容器进行并发的读，不需要加锁，也是读写分离的一种思想，但是如果读的时候有线程向容器加数据，此时读到的还是旧数据，因为写的时候不会锁住旧的容器。

缺点：新旧容器，如果数据大会产生很多内存垃圾，引起gc，不好

​          只能保证最终一致性，不能保证数据的实时一致性

### 队列

- 阻塞
  - offer：将元素e插入到队列末尾
  - poll：移除并获取队首元素
  - peek：获取队首元素
- 非阻塞（ArrayBlockingQueue）
  - put：向队列尾部插入元素，满了则等待
  - take：从队首取元素，为空则等待