---
layout: post
title: "elk部署"
description: ""
category: [elk]
tags: [elk]
---
{% include JB/setup %}

### 介绍
ELK是三个开源软件的缩写，分别为：Elasticsearch、Logstash、Kibana，后面还有一个fileBeat，它是一个轻量级的日志收集处理(Agent)，FileBeat占用的资源很少，适合在各个服务器上收集日志后传输给Logstash。

Elasticsearch是基于Lucene全文检索引擎框架，基于Java语言编写，是一个开源的分布式收缩引擎，提供收集、分析、存储数据三大功能，特点是：分布式、零配置、自动发现、索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。

Logstash是主要用来对日志进行收集、分析、过滤的，支持大量的数据获取方式。一般工作方式是C/S架构，client端安装在需要收集日志的主机上，server端负责将收到的各个节点日志进行过滤、修改操作在一并发往elasticsearchss上。

Kibana也是开源免费的工具，Kibana可以给Elasticsearch和Logstash提供很好的web界面，可以帮助汇总、分析和搜索重要的数据日志。

FileBeat属于Beats，是一个轻量型的日志采集器，早期的ELK架构中使用的是Logstash进行收集、解析并且过滤日志，但是Logstash对CPU、内存、IO等资源的消耗过高，相比于Logstash，Beats所占用的CPU和内存几乎可以忽略不记。目前Beats包括：Packagebeat(搜索网络流量数据)、Topbeat(搜集系统、进程和文件系统级别的CPU和内存使用情况等数据)、Filebeat(搜集文件数据)、Winlogbeat(搜集Windows事件日志数据)。

### 架构图

    架构1：这是最简单的一种ELK架构方式，优点时搭建简单，容易上手，缺点是Logstash消耗的资源比较大，运行占用的CPU和内存很高，另外也没有消息队列缓存，存在数据丢失的隐患。
          此架构由Logstash分布于各个节点上搜集相关日志、数据，并经过分析、过滤后发送给远端服务器上的Elasticsearch进行存储。Elasticsearch将数据以分片的形式压缩存储并提供多种API供用户查询，操作。用户亦可以更直观的通过配置Kibana Web方便的对日志查询，并根据数据生成报表。

![](https://s21.ax1x.com/2024/07/06/pkWAj2t.png)
        
    架构2：这种架构加入了消息队列机制，位于各个节点上的Logstash（采集，处理） Agent首先将数据/日志传输给Kafka(或者Redis)，并将队列中消息或数据间接传递给Logstash，
          Logstash过滤分析之后将数据传输给Elasticsearch进行存储，最后再由Kibana将日志和数据呈现给用户，而正是因为引入了Kafka(或者redis)，才使得远端的Logstash server因为故障停止运行之后，数据会先被存储下来，从而避免数据的丢失。

![](https://s21.ax1x.com/2024/07/06/pkWAzKf.png)

    架构3：这种架构将收集日志端换成了beats（采集），这样会更灵活，消耗资源会更少，扩展性也会更强。同时也可以配置Logstash（聚合，处理）和Elasticsearch集群用于支持大集群系统的运维日志数据监控和查询。

![](https://s21.ax1x.com/2024/07/06/pkWESr8.png)



### FileBeat的工作原理
    filebeat（读取文件，不对数据进行处理）由两个主要组件组成，prospectors（勘探者）和harvesters（收割机）。这两个组件协同工作将文件变动发送到指定的输出中。

![](https://s21.ax1x.com/2024/07/06/pkWEpqS.png)

    Haverster(收割机)：负责读取单个文件的内容。每个文件会启动一个Haverster，每个Haverster会逐行读取各个文件，并将文件内容发送到制定的输出中。Haverster负责打开和关闭文件，意味着Haverster运行的时候，文件描述符处于打开的状态，如果文件在收集中被重命名或者是被删除，Filebeat会继续读取此文件。所以在Haverster关闭之前，磁盘是不会被释放的。默认情况下filebeat会保持文件打开状态，直到达到close_inactive
    (如果此选项打开，filebeat会在指定的时间内将不会再更新的文件句柄关闭，时间从haverster读取最后一行的时间开始计时。如果文件句柄被关闭后，文件发生了变化，就会启动一个新的Haverster。关闭文件句柄的时间不取决于文件的修改时间，如果这个参数配置不合适，就有可能发生日志不实的情况，由scan_frequency参数所决定，默认是10s.Haverster使用内部时间戳来记录文件最后被搜集的时间。例如：设置5m则在Harvester读取文件的最后一行之后，开始倒计时5分钟，若5分钟内文件无变化，则关闭文件句柄。默认5m)
    
    prospector(勘探者)：负责管理Haverster并找到所有读取源。

```
filebeat.prospectors:
- input_type: log
  path:
  - /data/xxx.log
```
    prospector会找到/data/下的所有log文件，并为每一个文件启动一个Haverster。prospector会检查每个文件，看Haverster是否已经启动，是否需要启动，或者文件是否可以忽略。如果Haverster关闭，只有在文件大小发生变化的时候Prospector才会执行检查。只能检查本地文件。

filebeat如何记录文件的状态：

    将文件状态记录在文件中，默认是在/var/lib/filebeat/registry。此状态可以记住Haverster搜集文件的偏移量，若连接不上输出设备，如ES等，filebeat会记录发送前的最后一行，并再可以连接的时候继续发送。Filebeat在运行的时候，Prospector状态会被记录在内存中。Filebeat重启的时候，利用registry记录的状态来进行重建，用来还原到重启之前的状态。每个Prospector会为每个找到的文件记录一个状态，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前被收集。

Filebeat如何保证事件至少被输出一次：

    Filebeat之所以能保证事件至少被传递到配置的输出一次，没有数据丢失，是因为filebeat将每个事件的传递状态保存在文件中。在未得到输出方确认时，filebeat会尝试一直发送，直到得到回应。若filebeat在传输过程中被关闭，则不会再关闭之前确认所有时事件。任何在filebeat关闭之前为确认的时间，都会在filebeat重启之后重新发送。这可确保至少发送一次，但有可能会重复。可通过设置shutdown_timeout 参数来设置关闭之前的等待事件回应的时间（默认禁用）。


### logstash工作原理

Logstash事件处理有三个阶段：inputs → filters → outputs。是一个接收，处理，转发日志的工具。支持系统日志，webserver日志，错误日志，应用日志，总之包括所有可以抛出来的日志类型。
![](https://s21.ax1x.com/2024/07/06/pkWEPaQ.png)



